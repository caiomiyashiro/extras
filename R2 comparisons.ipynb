{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing R2 between different datasets!\n",
    "\n",
    "### \"Calculating R-squared on the testing data is a little tricky, as you have to remember what your baseline is. Your baseline projection is a mean of your training data.\" - https://stackoverflow.com/questions/25691127/r-squared-on-test-data\n",
    "\n",
    "### \"Second, let us see what using R2 for model choice/evaluation means. Suppose we choose from a set of predictions Y¯M that were generated using a model M:M∈, where  is the collection of models under consideration (in your example, this collection would contain Neural networks, random forests, elastic nets, ...). Since SST will remain constant amongst all the models, if minimizing R2 you will choose exactly the model that minimizes SSR. In other words, you will choose M∈M that produces the minimal square error loss!\" - https://stats.stackexchange.com/questions/83948/is-r-squared-value-appropriate-for-comparing-models\n",
    "\n",
    "$$SSE\\_residuals = \\sum_{i=0}^{m}(y_i - \\hat{y_i}) ^{2}$$\n",
    "\n",
    "$$SSE\\_total = \\sum_{i=0}^{m}(y_i - \\bar{y_i}) ^{2}$$\n",
    "\n",
    "$$R^2 = 1 - \\frac{SSE\\_residuals}{SSE\\_total}$$\n",
    "\n",
    "$R^2$ will be high when either:\n",
    "* $SSE\\_residuals$ is low --> Value close to 0 the ratio goes to 0\n",
    "* $SSE\\_total$ is high --> High value brings the ratio to 0\n",
    "\n",
    "$SSE\\_residuals$ are dependent on model, but the baseline / normalisation factor should be the same if we want to compare multiple runs. How are them in our dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TRAIN\n",
      "SSE_residuals_train 11926839144.44499\n",
      "SSE_total_train 81514569108.86674\n",
      "R2 train 0.8536845710548245\n",
      "\n",
      "--- validation\n",
      "SSE_residuals_validation 12026156003.659708\n",
      "SSE_total_validation 40894736795.43265\n",
      "R2 val 0.7059241128309974\n",
      "\n",
      "Ratio between SSE_residuals_train and SSE_residuals_validation 0.9917415956366694\n",
      "Ratio between SSE_total_train and SSE_total_validation 1.9932777539717714\n"
     ]
    }
   ],
   "source": [
    "\n",
    "SSE_residuals_train = np.sum((y_train - y_pred_train)**2)\n",
    "SSE_total_train = np.sum((y_train - np.mean(y_train))**2)\n",
    "r_2_train = 1 - (SSE_residuals_train)/SSE_total_train\n",
    "\n",
    "SSE_residuals_validation = np.sum((y_val - y_pred_val)**2)\n",
    "SSE_total_validation = np.sum((y_val - np.mean(y_val))**2)\n",
    "r_2_val = 1 - (SSE_residuals_validation)/SSE_total_validation\n",
    "\n",
    "\n",
    "print('--- TRAIN')\n",
    "print('SSE_residuals_train ' + str(SSE_residuals_train))\n",
    "print('SSE_total_train ' + str(SSE_total_train))\n",
    "print('R2 train ' + str(r_2_train))\n",
    "print('\\n--- validation')\n",
    "print('SSE_residuals_validation ' + str(SSE_residuals_validation))\n",
    "print('SSE_total_validation ' + str(SSE_total_validation))\n",
    "print('R2 val ' + str(r_2_val))\n",
    "\n",
    "print('\\nRatio between SSE_residuals_train and SSE_residuals_validation ' + str(SSE_residuals_train/SSE_residuals_validation))\n",
    "print('Ratio between SSE_total_train and SSE_total_validation ' + str(SSE_total_train/SSE_total_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As SSE_total_train was almost **double** of the SSE_total_validation the performance of the model in the validation set (SSE_residuals_validation) would have to be **double** (to be double as good in terms of SSE is reducing the SSE in half) in order for them to have the same value. Lets check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSE_residuals_train 11926839144.44499\n",
      "SSE_residuals_validation_SUPER 6013078001.829854\n",
      "\n",
      "Ratio between SSE_residuals_train and SSE_residuals_validation_SUPER 1.9834831912733388\n",
      "R2 train 0.8536845710548245\n",
      "R2 val 0.8529620564154987\n"
     ]
    }
   ],
   "source": [
    "SSE_residuals_validation_SUPER = np.sum((y_val - y_pred_val)**2) / 2 # dividing the error in half!\n",
    "r_2_val_SUPER = 1 - (SSE_residuals_validation_SUPER)/SSE_total_validation\n",
    "\n",
    "print('SSE_residuals_train ' + str(SSE_residuals_train))\n",
    "print('SSE_residuals_validation_SUPER ' + str(SSE_residuals_validation_SUPER))\n",
    "print('\\nRatio between SSE_residuals_train and SSE_residuals_validation_SUPER ' + str(SSE_residuals_train/SSE_residuals_validation_SUPER))\n",
    "\n",
    "print('R2 train ' + str(r_2_train))\n",
    "print('R2 val ' + str(r_2_val_SUPER))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# So what?\n",
    "\n",
    "## R2 is useful for evaluating different models performances on the **same** dataset. This avoids having different $SSE\\_total$ and therefore different baselines\n",
    "\n",
    "## If we are comparing training and validation (besides comparing them inside a CV setup) we can stablish the training baseline in order to calculate the validation R2, *i.e.*:\n",
    "\n",
    "$$R^2_{train} = 1 - \\frac{SSE\\_residuals_{train}}{SSE\\_total_{train}}$$  \n",
    "  \n",
    "  \n",
    "$$R^2_{val} = 1 - \\frac{SSE\\_residuals_{val}}{SSE\\_total_{train}}$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
